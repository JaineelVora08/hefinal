{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688483e-e256-409b-8191-de75dc895989",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgsales.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# returns data frame object which is like an excel spreadsheet\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# yeh df likhne se inspect hoga\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# use to_string() to print the entire DataFrame.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_rows) \n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:1394\u001b[0m, in \u001b[0;36mDataFrame.to_string\u001b[1;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_colwidth):\n\u001b[0;32m   1376\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mDataFrameFormatter(\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1378\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1393\u001b[0m     )\n\u001b[1;32m-> 1394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:962\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_string\u001b[1;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringFormatter\n\u001b[0;32m    961\u001b[0m string_formatter \u001b[38;5;241m=\u001b[39m StringFormatter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt, line_width\u001b[38;5;241m=\u001b[39mline_width)\n\u001b[1;32m--> 962\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[43mstring_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39mencoding)\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\string.py:29\u001b[0m, in \u001b[0;36mStringFormatter.to_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 29\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_string_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mshould_show_dimensions:\n\u001b[0;32m     31\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mdimensions_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\string.py:48\u001b[0m, in \u001b[0;36mStringFormatter._get_string_representation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_strcols()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# no need to wrap around just print the whole frame\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstrcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_wrap_around:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_join_multiline(strcols)\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\printing.py:525\u001b[0m, in \u001b[0;36m_TextAdjustment.adjoin\u001b[1;34m(self, space, *lists, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, space: \u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m*\u001b[39mlists, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjustfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjustify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\printing.py:56\u001b[0m, in \u001b[0;36madjoin\u001b[1;34m(space, *lists, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m maxLen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, lists))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, lst \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lists):\n\u001b[1;32m---> 56\u001b[0m     nl \u001b[38;5;241m=\u001b[39m \u001b[43mjustfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     nl \u001b[38;5;241m=\u001b[39m ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m lengths[i]] \u001b[38;5;241m*\u001b[39m (maxLen \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(lst))) \u001b[38;5;241m+\u001b[39m nl\n\u001b[0;32m     58\u001b[0m     newLists\u001b[38;5;241m.\u001b[39mappend(nl)\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\printing.py:518\u001b[0m, in \u001b[0;36m_TextAdjustment.justify\u001b[1;34m(self, texts, max_len, mode)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03mPerform ljust, center, rjust against string or list-like\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x\u001b[38;5;241m.\u001b[39mljust(max_len) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x\u001b[38;5;241m.\u001b[39mcenter(max_len) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('vgsales.csv')\n",
    "# returns data frame object which is like an excel spreadsheet\n",
    "# yeh df likhne se inspect hoga\n",
    "\n",
    "# print(df.to_string()) \n",
    "# use to_string() to print the entire DataFrame.\n",
    "\n",
    "print(pd.options.display.max_rows) \n",
    "# In my system the number is 60, which means that if the DataFrame contains more than 60 rows, the print(df) statement will return only the headers and the first and last 5 rows.\n",
    "# You can change the maximum rows number with the same statement\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81f7e200-6350-4375-b6d5-087fbb9eb763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16598, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e07c34f-cb11-41a6-a2a5-1b38ca39cb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16327.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8300.605254</td>\n",
       "      <td>2006.406443</td>\n",
       "      <td>0.264667</td>\n",
       "      <td>0.146652</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.537441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4791.853933</td>\n",
       "      <td>5.828981</td>\n",
       "      <td>0.816683</td>\n",
       "      <td>0.505351</td>\n",
       "      <td>0.309291</td>\n",
       "      <td>0.188588</td>\n",
       "      <td>1.555028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4151.250000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8300.500000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12449.750000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16600.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>41.490000</td>\n",
       "      <td>29.020000</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.570000</td>\n",
       "      <td>82.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rank          Year      NA_Sales      EU_Sales      JP_Sales  \\\n",
       "count  16598.000000  16327.000000  16598.000000  16598.000000  16598.000000   \n",
       "mean    8300.605254   2006.406443      0.264667      0.146652      0.077782   \n",
       "std     4791.853933      5.828981      0.816683      0.505351      0.309291   \n",
       "min        1.000000   1980.000000      0.000000      0.000000      0.000000   \n",
       "25%     4151.250000   2003.000000      0.000000      0.000000      0.000000   \n",
       "50%     8300.500000   2007.000000      0.080000      0.020000      0.000000   \n",
       "75%    12449.750000   2010.000000      0.240000      0.110000      0.040000   \n",
       "max    16600.000000   2020.000000     41.490000     29.020000     10.220000   \n",
       "\n",
       "        Other_Sales  Global_Sales  \n",
       "count  16598.000000  16598.000000  \n",
       "mean       0.048063      0.537441  \n",
       "std        0.188588      1.555028  \n",
       "min        0.000000      0.010000  \n",
       "25%        0.000000      0.060000  \n",
       "50%        0.010000      0.170000  \n",
       "75%        0.040000      0.470000  \n",
       "max       10.570000     82.740000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "# basic info about each NUMERICAL column in the data set\n",
    "\n",
    "# yaha rank has more records than year i.e. thode records me year hai hi nahi (null values)\n",
    "# aise me cleaning ke time we usually give some default value ya aise incomplete vaalo ko hata dete hai\n",
    "\n",
    "# The 25th percentile is the value below which 25% of the data falls.\n",
    "# Calculation of Percentiles:\n",
    "# Sort the data (if not already sorted): [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "# Find the 25th percentile:\n",
    "# Locate the 25% position: \n",
    "# 25%×(n+1), where \n",
    "# n is the number of elements.\n",
    "# 25%×(8+1)=2.25\n",
    "# Interpolate between the 2nd and 3rd data points: \n",
    "# 20+0.25×(30−20)=22.5\n",
    "# So, the 25th percentile for this dataset is 22.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689315f3-81b5-4dbd-8507-6df2e2661f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.values\n",
    "# returns 2d array - elements are rows in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326854d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25788\\1831706210.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# row ko access karne ke liye index - loc and iloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# loc me agar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# column ko access karne ke liye column name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#M1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis)\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[1;31m# we need to return a copy of ourselves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mnew_self\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m             \u001b[0maxis_int_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[0maxis_int_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[0mnew_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis_int_none\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNo axis named \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m for object type \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# row ko access karne ke liye index\n",
    "# M1 - loc and iloc\n",
    "# loc me agar ek hi number daala to refers to row\n",
    "df.loc[1]\n",
    "df.iloc[1, :]\n",
    "\n",
    "# yaha to row and column dono ke indexing 0,1,2... to how does it decide ki column ya row\n",
    "print(df[0:2]) \n",
    "# slicing a DataFrame using start:end without .loc or .iloc operates on the rows.\n",
    "\n",
    "# so df[a:b] operates on rows but df[a] operates on columns\n",
    "\n",
    "# column ko access karne ke liye column name\n",
    "#M1 - perefer bracket bcs dot me if colname=patameter to prob aa sakta hai\n",
    "age_column = df['Age'] \n",
    "# Returns a new DataFrame (not series bcs series me ek hi column) with only columns A and B\n",
    "df[['A', 'B']]\n",
    "#M2 - dot vaale me '' NAHI daalne\n",
    "age_column = df.Age\n",
    "# M3 - loc and iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      calories  duration\n",
      "day1       420        50\n",
      "day3       390        45\n",
      " \n",
      "50\n",
      " \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexing.py:966\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexing.py:1614\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only index by location with a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Can only index by location with a [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mday1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcalories\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print(df.iloc[0, 'calories']) - if index ='day1'... was not there\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexing.py:1690\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1690\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1691\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1692\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexing.py:968\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 968\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[1;31mValueError\u001b[0m: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
     ]
    }
   ],
   "source": [
    "# loc me you can choose row/column based on their name\n",
    "# iloc me you can choose row/column based on their index - but print to column name hi hoga dono cases me\n",
    "\n",
    "data = {\n",
    "  \"calories\": [420, 380, 390],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "\n",
    "#load data into a DataFrame object:\n",
    "df = pd.DataFrame(data)\n",
    "df = pd.DataFrame(data, index = [\"day1\", \"day2\", \"day3\"])\n",
    "# ek se zyada rows return karni ho to use 2 brackets \n",
    "# 1 bracket me vo i,j th element return karega\n",
    "# but [[i,j]] me it will give ith and jth row (NOT ith to jth - TO ke liye we use : ) - bahar vaale [] ke liye [i,j] is 1st element and yaha ek hi element aur jab ek hi element in loc/iloc - it refers to rows\n",
    "# yaha 3 fir 1 print hoga - how we specified bhale org me 1,3 hai\n",
    "print(df.loc[[\"day3\", \"day1\"]])\n",
    "print(' ')\n",
    "print(df.iloc[0, 1])\n",
    "print(' ')\n",
    "\n",
    "# in dono -single aur multiple rows ke method of printing dekh lena\n",
    "print(df.iloc[0])\n",
    "print(' ')\n",
    "print(df.iloc[[0, 1]])\n",
    "print(' ')\n",
    "\n",
    "print(df.iloc[\"day1\", 'calories'])\n",
    "# print(df.iloc[0, 'calories']) - if index ='day1'... was not there\n",
    "print(' ')\n",
    "print(df.iloc[0:1, 0:2])\n",
    "print(' ')\n",
    "print(df.loc[0])\n",
    "# this row is returned as a pandas series\n",
    "\n",
    "# for column slicing i.e. to get a few columns\n",
    "newdf.loc[[1,2],['C','D']]\n",
    "# pehle bracket me kaunse rows chahiye aur doosre me kaunse columns \n",
    "# loc returns a new data frame - copy\n",
    "\n",
    "#for all rows: same for columns\n",
    "# : me bracket NAHI so - sirf : , NOT [:]\n",
    "newdf.loc[:,['C','D']]\n",
    "newdf.iloc[:,[2,3]]\n",
    "\n",
    "# note: slicing me [a:b] me:\n",
    "# loc-Inclusive BUT iloc-Exclusive\n",
    "\n",
    "# You need loc/iloc to access a particular element,\n",
    "df.at[0, 'A'] \n",
    "# o\n",
    "df.iat[0, 0]\n",
    "\n",
    "# prefer loc bcs yaha copy/view ka ho sakta hai and it might be copy sometimes to org dataframe me change nahi dikhega\n",
    "df['Name'][0]='Jai'\n",
    "df.loc['Name'][0]='Jai'\n",
    "\n",
    "df['Name'] \n",
    "# yeh syntax se dataframe return hoga and not series - unlike loc\n",
    "\n",
    "df.loc[2] = ['John', 'Smith', 'JohnSmith@email.com']\n",
    "df.loc[2, ['last', 'email']] = ['Doe', 'JohnDoe@email.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74b476ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saare columns ke liye\n",
    "newdf.columns\n",
    "# saare rows ke liye\n",
    "newdf.index\n",
    "\n",
    "# ya use loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a21a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       5 non-null      int64  \n",
      " 1   B       3 non-null      float64\n",
      " 2   C       4 non-null      float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 252.0 bytes\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [np.nan, 2, np.nan, 4, 5],\n",
    "    'C': [1, 2, None, 4, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.info()\n",
    "\n",
    "# it gives us data type and non null count of each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>marks</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>44</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>23</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  marks city\n",
       "0    a     10    e\n",
       "1    b     20    f\n",
       "2    c     44    g\n",
       "3    d     23    h"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {\n",
    "    \"name\": ['a','b','c','d'],\n",
    "    \"marks\": [10,20,44,23],\n",
    "    \"city\":['e','f','g','h']\n",
    "}\n",
    "\n",
    "# keys become columns and values become rows\n",
    "\n",
    "df1 = pd.DataFrame(dict1)\n",
    "# dataframe is like an excel sheet and we can use numpy\n",
    "# df is rows and column and series is diff rows of same column\n",
    "df1\n",
    "\n",
    "dict1.['name']\n",
    "df.['name']\n",
    "# df me indexing bhi hoga\n",
    "'''\n",
    "['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com']\n",
    "\n",
    "0    CoreyMSchafer@gmail.com\n",
    "1          JaneDoe@email.com\n",
    "2          JohnDoe@email.com\n",
    "Name: email, dtype: object\n",
    "'''\n",
    "\n",
    "df.to_csv('friends.csv')\n",
    "# excel file me convert\n",
    "\n",
    "df.to_csv('friends2.csv',index=False)\n",
    "# 0,1,2,3... nikal jaayega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011affb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>16599</td>\n",
       "      <td>Know How 2</td>\n",
       "      <td>DS</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>7G//AMES</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16597</th>\n",
       "      <td>16600</td>\n",
       "      <td>Spirits &amp; Spells</td>\n",
       "      <td>GBA</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Wanadoo</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank              Name Platform    Year     Genre Publisher  NA_Sales  \\\n",
       "16596  16599        Know How 2       DS  2010.0    Puzzle  7G//AMES      0.00   \n",
       "16597  16600  Spirits & Spells      GBA  2003.0  Platform   Wanadoo      0.01   \n",
       "\n",
       "       EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "16596      0.01       0.0          0.0          0.01  \n",
       "16597      0.00       0.0          0.0          0.01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n",
    "df['name'].head(2)\n",
    "df[['name','marks']].head(2)\n",
    "# start ke n rows\n",
    "# if n>total rows to shows all rows (NOT ERROR)\n",
    "# if no n then pehle 5 dikhayega\n",
    "# For negative values of n, last |n| ko nikaal ke baaki ka return karega, equivalent to df[:n]\n",
    "\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343cff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.rand(34))\n",
    "# ser\n",
    "ser2 = pd.Series(x for x in range(1,11))\n",
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711ffdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10, 5), indices imply (9, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# doubt - is index vaala needed?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m newdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m newdf\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (10, 5), indices imply (9, 5)"
     ]
    }
   ],
   "source": [
    "# doubt - index vaala not needed agar normal index chahiye\n",
    "newdf = pd.DataFrame(np.random.rand(10,5),index=np.arange(2,11))\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voraj\\AppData\\Local\\Temp\\ipykernel_25788\\819611522.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  newdf[0][0]='jai'\n",
      "C:\\Users\\voraj\\AppData\\Local\\Temp\\ipykernel_25788\\819611522.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'jai' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  newdf[0][0]='jai'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     object\n",
       "1    float64\n",
       "2    float64\n",
       "3    float64\n",
       "4    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ser)\n",
    "type(newdf)\n",
    "\n",
    "# it gives ki kaunse column me kaunsa data type (bcs har column ka same data type)\n",
    "newdf.dtypes\n",
    "\n",
    "# abhi it is possible ki numeric vaala column might have object data type, to uspe mean() and stuff NAHI laga sakte - so to check we can use dtypes\n",
    "# Jab Nan values ko numbers me convert karna hai use float bcs type(np.nan) is float\n",
    "\n",
    "# casting data type\n",
    "# 1. No Nan - direct to int\n",
    "df['age'] = df['age'].astype(int)\n",
    "# 2. If nan - pehle fillnan fir to int YA conv to floats\n",
    "df['age'] = df['age'].astype(float)\n",
    "\n",
    "# poore df ke liye\n",
    "df.astype(float)\n",
    "\n",
    "\n",
    "# abhi if you do:\n",
    "newdf[0][0]='jai'\n",
    "newdf.dtypes\n",
    "# now column1 ka data type becomes object as different data types in 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "634e86ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jai', 0.8987070762472977, 0.11809491192131882,\n",
       "        0.48970368576480927, 0.7021071653396315],\n",
       "       [0.5602364037576205, 0.33169985744714936, 0.639556183528518,\n",
       "        0.1025739564776591, 0.45781925654258726],\n",
       "       [0.11920966694106083, 0.3709520771087744, 0.8516898190583134,\n",
       "        0.9554118466150854, 0.6292243380806274],\n",
       "       [0.09030544464332557, 0.11517224519628477, 0.14290720623925346,\n",
       "        0.5455684667392982, 0.23992211284974618],\n",
       "       [0.31174179476328734, 0.7297440230028405, 0.17598685117296753,\n",
       "        0.020007744487270607, 0.8191069511371581],\n",
       "       [0.6332386303082705, 0.4722920253077919, 0.42514264676721325,\n",
       "        0.7076018294655303, 0.001918966761785379],\n",
       "       [0.6648584561683468, 0.0694685060987208, 0.4471419381651116,\n",
       "        0.23599338059867947, 0.0012309896941165022],\n",
       "       [0.5600802115955038, 0.0948815651672128, 0.47629987445134214,\n",
       "        0.5863269411060148, 0.21424828101359783],\n",
       "       [0.8419731145214686, 0.07754335023509396, 0.6701051397135679,\n",
       "        0.3280712905752967, 0.08773929456268448],\n",
       "       [0.1370846843071093, 0.28965410162725924, 0.8821996310204374,\n",
       "        0.9897881140634978, 0.8189961324992393]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.to_numpy()\n",
    "# convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jai</td>\n",
       "      <td>0.560236</td>\n",
       "      <td>0.11921</td>\n",
       "      <td>0.090305</td>\n",
       "      <td>0.311742</td>\n",
       "      <td>0.633239</td>\n",
       "      <td>0.664858</td>\n",
       "      <td>0.56008</td>\n",
       "      <td>0.841973</td>\n",
       "      <td>0.137085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.898707</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>0.370952</td>\n",
       "      <td>0.115172</td>\n",
       "      <td>0.729744</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.094882</td>\n",
       "      <td>0.077543</td>\n",
       "      <td>0.289654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.118095</td>\n",
       "      <td>0.639556</td>\n",
       "      <td>0.85169</td>\n",
       "      <td>0.142907</td>\n",
       "      <td>0.175987</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.447142</td>\n",
       "      <td>0.4763</td>\n",
       "      <td>0.670105</td>\n",
       "      <td>0.8822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.489704</td>\n",
       "      <td>0.102574</td>\n",
       "      <td>0.955412</td>\n",
       "      <td>0.545568</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.235993</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>0.328071</td>\n",
       "      <td>0.989788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.702107</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>0.629224</td>\n",
       "      <td>0.239922</td>\n",
       "      <td>0.819107</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.214248</td>\n",
       "      <td>0.087739</td>\n",
       "      <td>0.818996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0       jai  0.560236   0.11921  0.090305  0.311742  0.633239  0.664858   \n",
       "1  0.898707    0.3317  0.370952  0.115172  0.729744  0.472292  0.069469   \n",
       "2  0.118095  0.639556   0.85169  0.142907  0.175987  0.425143  0.447142   \n",
       "3  0.489704  0.102574  0.955412  0.545568  0.020008  0.707602  0.235993   \n",
       "4  0.702107  0.457819  0.629224  0.239922  0.819107  0.001919  0.001231   \n",
       "\n",
       "          7         8         9  \n",
       "0   0.56008  0.841973  0.137085  \n",
       "1  0.094882  0.077543  0.289654  \n",
       "2    0.4763  0.670105    0.8822  \n",
       "3  0.586327  0.328071  0.989788  \n",
       "4  0.214248  0.087739  0.818996  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to take transpose\n",
    "newdf.T\n",
    "\n",
    "# swap two rows\n",
    "\n",
    "#m1\n",
    "# Swap rows 1 and 3 (indices 1 and 3)\n",
    "temp = df.loc[1].copy()  # Temporarily store row 1\n",
    "df.loc[1] = df.loc[3]    # Assign row 3 to row 1\n",
    "df.loc[3] = temp         # Assign the stored row to row 3\n",
    "\n",
    "#m2\n",
    "df.iloc[[1, 3]] = df.iloc[[3, 1]].values\n",
    "'''\n",
    "This works because .values extracts the values as a NumPy array, preventing overlaps during the assignment. The swapping happens correctly.\n",
    "This detaches the values from the original pandas DataFrame, ensuring the assignment operation does not involve overlapping or interdependent operations.\n",
    "df.iloc[[3, 1]].values creates a \"snapshot\" of the data before the assignment.\n",
    "\n",
    "\n",
    "When you write df.iloc[[1, 3]] = df.iloc[[3, 1]], pandas does the following:\n",
    "Assigns df.iloc[3] to df.iloc[1].\n",
    "Assigns df.iloc[1] (which is already modified) to df.iloc[3].\n",
    "so it does not work\n",
    "'''\n",
    "\n",
    "'''\n",
    "What .values Does: (can also use to_numpy())\n",
    "For a DataFrame: Returns the entire data as a 2D NumPy array.\n",
    "For a Series: Returns the data as a 1D NumPy array.\n",
    "So useful jab koi func numpy arrays pe hi kaam karta ho\n",
    "It can also be useful when performing advanced operations on the raw data (such as element-wise transformations) where you need the full flexibility of NumPy arrays.\n",
    "\n",
    "Original DataFrame:\n",
    "   A  B  C\n",
    "0  1  4  7\n",
    "1  2  5  8\n",
    "2  3  6  9\n",
    "\n",
    "NumPy array from .values:\n",
    "[[1 4 7]\n",
    " [2 5 8]\n",
    " [3 6 9]]\n",
    "\n",
    "'''\n",
    "\n",
    "#m3\n",
    "# Reorder the rows to swap rows 1 and 3\n",
    "df = df.reindex([0, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f6188a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.137085</td>\n",
       "      <td>0.289654</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.989788</td>\n",
       "      <td>0.818996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841973</td>\n",
       "      <td>0.077543</td>\n",
       "      <td>0.670105</td>\n",
       "      <td>0.328071</td>\n",
       "      <td>0.087739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.56008</td>\n",
       "      <td>0.094882</td>\n",
       "      <td>0.476300</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>0.214248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.664858</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.447142</td>\n",
       "      <td>0.235993</td>\n",
       "      <td>0.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.633239</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311742</td>\n",
       "      <td>0.729744</td>\n",
       "      <td>0.175987</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.819107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090305</td>\n",
       "      <td>0.115172</td>\n",
       "      <td>0.142907</td>\n",
       "      <td>0.545568</td>\n",
       "      <td>0.239922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11921</td>\n",
       "      <td>0.370952</td>\n",
       "      <td>0.851690</td>\n",
       "      <td>0.955412</td>\n",
       "      <td>0.629224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560236</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.639556</td>\n",
       "      <td>0.102574</td>\n",
       "      <td>0.457819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jai</td>\n",
       "      <td>0.898707</td>\n",
       "      <td>0.118095</td>\n",
       "      <td>0.489704</td>\n",
       "      <td>0.702107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "9  0.137085  0.289654  0.882200  0.989788  0.818996\n",
       "8  0.841973  0.077543  0.670105  0.328071  0.087739\n",
       "7   0.56008  0.094882  0.476300  0.586327  0.214248\n",
       "6  0.664858  0.069469  0.447142  0.235993  0.001231\n",
       "5  0.633239  0.472292  0.425143  0.707602  0.001919\n",
       "4  0.311742  0.729744  0.175987  0.020008  0.819107\n",
       "3  0.090305  0.115172  0.142907  0.545568  0.239922\n",
       "2   0.11921  0.370952  0.851690  0.955412  0.629224\n",
       "1  0.560236  0.331700  0.639556  0.102574  0.457819\n",
       "0       jai  0.898707  0.118095  0.489704  0.702107"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. sort acc to index\n",
    "newdf.sort_index(axis=0,ascending=False,inplace=True)\n",
    "# axis = 0 means rows\n",
    "# axis = 1 means columns\n",
    "\n",
    "# 2. sort acc to values\n",
    "newdf_sorted = newdf.sort_values(by='A', axis=1)\n",
    "\n",
    "df.sort_values(by=['last', 'first'], ascending=False)\n",
    "# ek hi hai to ascending=False applies globally to all columns.\n",
    "df.sort_values(by=['last', 'first'], ascending=[False, True], inplace=True)\n",
    "# The secondary sorting only applies to the rows that have equal values in the primary column.\n",
    "# ie last ke hisab se sorting hoga and if values come to be same, first dekho\n",
    "# agar secondary order nahi diya to pandas retains the relative order of those rows as they appear in the DataFrame (based on the original index order)\n",
    "\n",
    "# firse org vaala chahiye to:\n",
    "newdf.sort_index(axis=0,ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "df['last'].sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ConvertedComp'].nlargest(10)\n",
    "# nlargest baadme (column pe nlargest lagane se) se series return hoga\n",
    "# isse sirf top 10 salaries return honge NOT the other values\n",
    "df.nlargest(10, 'ConvertedComp')\n",
    "# nlargest pehle se - dataframe return hoga - so ypu get all info along with the saleries\n",
    "\n",
    "df.nsmallest(10, 'ConvertedComp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index se hum column name se hum loc use kar sakte hai\n",
    "\n",
    "df.set_index('email', inplace=True)\n",
    "\n",
    "'''\n",
    "    first\tlast\temail\n",
    "0\tCorey\tSchafer\tCoreyMSchafer@gmail.com\n",
    "1\tJane\tDoe\tJaneDoe@email.com\n",
    "2\tJohn\tDoe\tJohnDoe@email.com\n",
    "\n",
    "\n",
    "email                   first\tlast\n",
    "CoreyMSchafer@gmail.com\tCorey\tSchafer\n",
    "JaneDoe@email.com\t    Jane\tDoe\n",
    "JohnDoe@email.com\t    John\tDoe\n",
    "'''\n",
    "\n",
    "# direct loading ke time also you can set index\n",
    "# df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent')\n",
    "\n",
    "#fir se numbers org chahiye as index\n",
    "newdf.reset_index()\n",
    "# neeche vaala when drop kiya ho tab use upar to we need that column to come back\n",
    "#this adds another column called index which contains original indices. Agar vo nahi chahiye to:\n",
    "newdf.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "# set index se hum particular column ko index banake, ROWS vaale indexes/headings control karte hai\n",
    "# to control column vaale indexes/headings:\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "\n",
    "# Renaming columns\n",
    "# M1\n",
    "df.rename(columns={'A': 'X', 'B': 'Y', 'C': 'Z'}, inplace=True)\n",
    "print(df)\n",
    "\n",
    "# M2\n",
    "newdf.columns = list(\"ABC\")\n",
    "# ya\n",
    "newdf.columns = ['user_id', 'full_name', 'residence']\n",
    "\n",
    "# M3\n",
    "df.columns.values[0] = \"user_id\"\n",
    "df.columns.values[1] = \"full_name\"\n",
    "df.columns.values[2] = \"residence\"\n",
    "df.columns.values[3] = \"birthdate\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd7ea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2 = newdf\n",
    "# this is view NOT copy ... so changes in either will change in BOTH\n",
    "\n",
    "# for copy\n",
    "newdf2=newdf[:]\n",
    "#OR\n",
    "newdf2=newdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee14be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jai</td>\n",
       "      <td>0.898707</td>\n",
       "      <td>0.118095</td>\n",
       "      <td>0.489704</td>\n",
       "      <td>0.702107</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560236</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.639556</td>\n",
       "      <td>0.102574</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11921</td>\n",
       "      <td>0.370952</td>\n",
       "      <td>0.851690</td>\n",
       "      <td>0.955412</td>\n",
       "      <td>0.629224</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090305</td>\n",
       "      <td>0.115172</td>\n",
       "      <td>0.142907</td>\n",
       "      <td>0.545568</td>\n",
       "      <td>0.239922</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311742</td>\n",
       "      <td>0.729744</td>\n",
       "      <td>0.175987</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.819107</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.633239</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.664858</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.447142</td>\n",
       "      <td>0.235993</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.56008</td>\n",
       "      <td>0.094882</td>\n",
       "      <td>0.476300</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>0.214248</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841973</td>\n",
       "      <td>0.077543</td>\n",
       "      <td>0.670105</td>\n",
       "      <td>0.328071</td>\n",
       "      <td>0.087739</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.137085</td>\n",
       "      <td>0.289654</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.989788</td>\n",
       "      <td>0.818996</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4     11\n",
       "0       jai  0.898707  0.118095  0.489704  0.702107   500\n",
       "1  0.560236  0.331700  0.639556  0.102574  0.457819  None\n",
       "2   0.11921  0.370952  0.851690  0.955412  0.629224  None\n",
       "3  0.090305  0.115172  0.142907  0.545568  0.239922  None\n",
       "4  0.311742  0.729744  0.175987  0.020008  0.819107  None\n",
       "5  0.633239  0.472292  0.425143  0.707602  0.001919  None\n",
       "6  0.664858  0.069469  0.447142  0.235993  0.001231  None\n",
       "7   0.56008  0.094882  0.476300  0.586327  0.214248  None\n",
       "8  0.841973  0.077543  0.670105  0.328071  0.087739  None\n",
       "9  0.137085  0.289654  0.882200  0.989788  0.818996  None"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rather than directly setting value use loc\n",
    "# loc ke [row name, column name] NOT row and column indices\n",
    "# so vo list vaale me it will be newdf.loc[0,'A']=500\n",
    "\n",
    "# here org 11 karke column DNE, to it will create a column 11 and baaki ke values will be NaN\n",
    "newdf.loc[0,11]=500\n",
    "print(newdf.loc[0])\n",
    "# loc me agar ek hi paramter pass kiya to it will be the row name\n",
    "\n",
    "#Another way to create a column\n",
    "newdf[11] = None  # Add a new column\n",
    "newdf.loc[0, 11] = 500\n",
    "\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]})\n",
    "# Adding a new column with a list of values\n",
    "df['Salary'] = [50000, 60000, 70000]\n",
    "\n",
    "# Renaming columns\n",
    "df.columns = ['first_name', 'last_name', 'email']\n",
    "# isse column ke headings me farak padega NOT whole column\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "# df['email'] = df['email'].str.lower()\n",
    "df.rename(columns={'first_name': 'first', 'last_name': 'last'}, inplace=True)\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "\n",
    "\n",
    "filt = df['LanguageWorkedWith'].str.contains('Python', na=False)\n",
    "df.loc[filt,'Name']\n",
    "\n",
    "'''\n",
    "na=False:\n",
    "If a value in the column is NaN (missing), it would normally result in a NaN in the output.\n",
    "By setting na=False, any NaN values in the column are treated as if they do not contain the substring, and False is returned for those rows.\n",
    "\n",
    "filt me boolean series is stored NOT all the rows which contain python\n",
    "\n",
    "Respondent\n",
    "1         True\n",
    "2         True\n",
    "'''\n",
    "\n",
    "filt = (df['last'] == 'Schafer')\n",
    "'''\n",
    "0         True\n",
    "1         True\n",
    "'''\n",
    "# this also gives series object with true values NOT a dataframe with obj that meet our criteria\n",
    "# so now we have to apply this to our dataframe\n",
    "# true/false abhi correspond to our rows\n",
    "# this means ki jaha jaha False hai, un rows ka\n",
    "# usually loc me hum names/labels use karte hai BUT YOU CAN ALSO USE LOC WITH FILTERS\n",
    "df.loc[~filt, 'email']\n",
    "#ya - both eqv\n",
    "df[filt]\n",
    "df[df['last'] == 'Schafer']\n",
    "# after this dataframe is retured (filt vala series print NAHI hoga)\n",
    "\n",
    "\n",
    "filt = (df['last'] == 'Schafer') | (df['first'] == 'John')\n",
    "\n",
    "\n",
    "#another eg\n",
    "high_salary = (df['Converted']>7000)\n",
    "df.loc[high_salary,['Country','Lang']]\n",
    "# abhi agar in countries ka hi result chahiye - to loc me you can type list -doubt\n",
    "# to we might do filter ki if country==us || country==uk and aise ek ek karke \n",
    "countries = ['us','uk','ind']\n",
    "filt = df.['Country'].isin(countries)\n",
    "df.loc[filt,'Country']\n",
    "\n",
    "\n",
    "# saare emails ko lowercase karne\n",
    "df['email'] = df['email'].str.lower()\n",
    "df['email'] = df['email'].apply(lambda x: x.lower())\n",
    "df['email'].apply(len)\n",
    "\n",
    "len(df['email'])\n",
    "\n",
    "df.apply(len)\n",
    "\n",
    "'''\n",
    "df.apply(len, axis='columns') - default is rows\n",
    "isse len vaala series pe lagega (NOT on whole df) so we will know ki har series me kitne elements\n",
    "\n",
    "0    3\n",
    "1    3\n",
    "2    3\n",
    "dtype: int64\n",
    "\n",
    "columns se vo row wise dekhega i.e. indices are of rows\n",
    "AND vice versa - doubt why??\n",
    "'''\n",
    "\n",
    "\n",
    "# apply - series and dataframe\n",
    "def update_email(email):\n",
    "    return email.upper()\n",
    "df['email'].apply(update_email)\n",
    "# sirf apply se series return hogi so do df[email] = ...\n",
    "\n",
    "df.apply(pd.Series.min)\n",
    "'''\n",
    "Har series ka min element dega\n",
    "first                      Corey\n",
    "last                         Doe\n",
    "email    coreymschafer@gmail.com\n",
    "dtype: object\n",
    "'''\n",
    "df.apply(lambda x: x.min())\n",
    "# lambda works on series obj\n",
    "\n",
    "\n",
    "#map - series\n",
    "# used to replace values in series with other values\n",
    "df['first'].map({'Corey': 'Chris', 'Jane': 'Mary'})\n",
    "df['Hobby'] = df['Hobby'].map({'Y':'T','N':'F'})\n",
    "# agar subs nai kiye to org names NAHI rahenge aur vo Nan me convert ho jaayega.\n",
    "# to prevent, use replace\n",
    "\n",
    "\n",
    "#applymap - only on df\n",
    "# upar apply on df applies on series and... but series applies on har value - applymap me every element of df\n",
    "df.applymap(len)\n",
    "# df retruns with har element pe len lagega\n",
    "df.applymap(str.lower)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# replace\n",
    "df['first'] = df['first'].replace({'Corey': 'Chris', 'Jane': 'Mary'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ec55a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25788\\2167074385.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;36m2\u001b[0m       \u001b[0mJohnDoe\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m       \u001b[0mJohn\u001b[0m \u001b[0mDoe\u001b[0m        \u001b[0mJohn\u001b[0m    \u001b[0mDoe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m '''\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Tony'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m '''\n\u001b[0;32m     43\u001b[0m \u001b[0memail\u001b[0m   \u001b[0mfull_name\u001b[0m       \u001b[0mfirst\u001b[0m   \u001b[0mlast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;36m0\u001b[0m       \u001b[0mCoreyMSchafer\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mgmail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m \u001b[0mCorey\u001b[0m \u001b[0mSchafer\u001b[0m   \u001b[0mCorey\u001b[0m   \u001b[0mSchafer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "people = {\n",
    "    'first': ['Corey', 'Jane', 'John'], \n",
    "    'last': ['Schafer', 'Doe', 'Doe'], \n",
    "    'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com']\n",
    "}\n",
    "df = pd.DataFrame(people)\n",
    "\n",
    "# yeh karne se naya column bhi add ho jaayega\n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "'''\n",
    "\tfirst\tlast\temail\t                full_name\n",
    "0\tCorey\tSchafer\tCoreyMSchafer@gmail.com\tCorey Schafer\n",
    "1\tJane\tDoe\t    JaneDoe@email.com\t    Jane Doe\n",
    "2\tJohn\tDoe\t    JohnDoe@email.com\t    John Doe\n",
    "'''\n",
    "\n",
    "#to drop column\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "df = df.drop(columns=['first']).reset_index(drop=True)\n",
    "#to drop row\n",
    "df.drop(index=4)\n",
    "'''\n",
    "email\tfull_name\n",
    "0\tCoreyMSchafer@gmail.com\tCorey Schafer\n",
    "1\tJaneDoe@email.com\tJane Doe\n",
    "2\tJohnDoe@email.com\tJohn Doe\n",
    "'''\n",
    "\n",
    "\n",
    "# df['full_name'].str.split(' ') se we get split karke a list\n",
    "# 0 [fname,lname]\n",
    "# 1 [fname,lname] ... vaise\n",
    "df['full_name'].str.split(' ', expand=True)\n",
    "# expand=True se we assign this list in 2 different columns\n",
    "# isse ek df return hoga aur neeche assignment kiya\n",
    "'''\n",
    "        0\t1\n",
    "0\tCorey\tSchafer\n",
    "1\tJane\tDoe\n",
    "2\tJohn\tDoe\n",
    "'''\n",
    "\n",
    "df[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n",
    "'''\n",
    "email\tfull_name\tfirst\tlast\n",
    "0\tCoreyMSchafer@gmail.com\tCorey Schafer\tCorey\tSchafer\n",
    "1\tJaneDoe@email.com\tJane Doe\tJane\tDoe\n",
    "2\tJohnDoe@email.com\tJohn Doe\tJohn\tDoe\n",
    "'''\n",
    "\n",
    "filt = df['last'] == 'Doe'\n",
    "df.drop(index=df[filt].index)\n",
    "# df[filt].index me it gives index of rows jispe filter lage\n",
    "# ie vo rows drop kar do jaha last name = Doe ho\n",
    "'''\n",
    "email\tfull_name\tfirst\tlast\n",
    "0\tCoreyMSchafer@gmail.com\tCorey Schafer\tCorey\tSchafer\n",
    "1\tJaneDoe@email.com\tJane Doe\tJane\tDoe\n",
    "2\tJohnDoe@email.com\tJohn Doe\tJohn\tDoe\n",
    "3\tIronMan@avenge.com\tNaN\tTony\tStark\n",
    "4\tCap@avenge.com\tNaN\tSteve\tRoger\n",
    "\n",
    "email\tfull_name\tfirst\tlast\n",
    "0\tCoreyMSchafer@gmail.com\tCorey Schafer\tCorey\tSchafer\n",
    "3\tIronMan@avenge.com\tNaN\tTony\tStark\n",
    "4\tCap@avenge.com\tNaN\tSteve\tRogers\n",
    "'''\n",
    "\n",
    "\n",
    "#append\n",
    "\n",
    "#1. Append a Dictionary\n",
    "df.append({'first': 'Tony'}, ignore_index=True)\n",
    "df_new = df.append({'first': 'Tony', 'last': 'Stark'}, ignore_index=True)\n",
    "'''\n",
    "email\tfull_name\tfirst\tlast\n",
    "0\tCoreyMSchafer@gmail.com\tCorey Schafer\tCorey\tSchafer\n",
    "1\tJaneDoe@email.com\tJane Doe\tJane\tDoe\n",
    "2\tJohnDoe@email.com\tJohn Doe\tJohn\tDoe\n",
    "3\tNaN\t                NaN     \tTony\tNaN\n",
    "\n",
    "agar ignore_index=False to\n",
    "   first      last\n",
    "0  Corey  Schafer\n",
    "1   Jane      Doe\n",
    "2   John      Doe\n",
    "0   Tony      NaN\n",
    "'''\n",
    "\n",
    "'''\n",
    "df.append(other, ignore_index=False, verify_integrity=False, sort=False)\n",
    "\n",
    "other: The data to append.\n",
    "Can be another DataFrame, Series, or dictionary-like object.\n",
    "\n",
    "ignore_index (default: False):\n",
    "If True, a new sequential index is assigned to the resulting DataFrame, ignoring the index of other.\n",
    "\n",
    "verify_integrity (default: False):\n",
    "If True, raises a ValueError if the index of other contains duplicates.\n",
    "\n",
    "sort (default: False):\n",
    "If True, sorts columns if the columns in other differ from the columns in the original DataFrame.'''\n",
    "\n",
    "# 2. Append Another DataFrame\n",
    "people = {\n",
    "    'first': ['Tony', 'Steve'], \n",
    "    'last': ['Stark', 'Rogers'], \n",
    "    'email': ['IronMan@avenge.com', 'Cap@avenge.com']\n",
    "}\n",
    "df2 = pd.DataFrame(people)\n",
    "df.append(df2, ignore_index=True, sort=False)\n",
    "# ignoreindex=False se 01012 aise hoga ki org lists ke indices aayende, =True se proper vaale aayenge\n",
    "# sort=True - columns to be sorted alphabetically in the final DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf32abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conforming data to a new index or adding/removing rows/columns as per a specified order. Missing values are introduced for any new labels not present in the original data.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data, index=[0, 1, 2])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Reindex with new row indices\n",
    "new_index = [0, 2, 4]\n",
    "df_reindexed = df.reindex(index=new_index)\n",
    "print(\"\\nReindexed DataFrame:\")\n",
    "print(df_reindexed)\n",
    "\n",
    "'''\n",
    "Original DataFrame:\n",
    "   A  B\n",
    "0  1  4\n",
    "1  2  5\n",
    "2  3  6\n",
    "\n",
    "Reindexed DataFrame:\n",
    "     A    B\n",
    "0  1.0  4.0\n",
    "2  3.0  6.0\n",
    "4  NaN  NaN\n",
    "'''\n",
    "\n",
    "# Reindex columns\n",
    "new_columns = ['A', 'C']\n",
    "df_reindexed = df.reindex(columns=new_columns)\n",
    "print(\"\\nReindexed Columns:\")\n",
    "print(df_reindexed)\n",
    "\n",
    "'''\n",
    "Reindexed Columns:\n",
    "     A   C\n",
    "0  1.0 NaN\n",
    "1  2.0 NaN\n",
    "2  3.0 NaN\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "DataFrame.reindex(labels=None, index=None, columns=None, axis=None, method=None, fill_value=None, limit=None, tolerance=None)\n",
    "\n",
    "labels / index: The new index for the rows. Can be a list or array.\n",
    "columns: The new index for the columns.\n",
    "axis: 0 or 'index' to reindex rows, 1 or 'columns' to reindex columns.\n",
    "method: The filling method for missing values.\n",
    "'ffill' (forward fill): Fill with the previous value.\n",
    "'bfill' (backward fill): Fill with the next value.\n",
    "fill_value: Value to set for missing data when no fill method is specified.\n",
    "inplace: If True, modifies the original DataFrame.\n",
    "tolerance: Maximum distance between original and new labels for inexact matches. Its used with ffill ya bfill\n",
    "tolerance=7: Only allow forward filling if the distance between the original index and the new index is less than or equal to 7.\n",
    "\n",
    "Eg\n",
    "df = pd.DataFrame({'A': [1, 2, 3]}, index=[10, 20, 30])\n",
    "new_index = [5, 15, 25]\n",
    "df_reindexed = df.reindex(index=new_index, method='ffill', tolerance=7)\n",
    "\n",
    "       A\n",
    "5    NaN\n",
    "15   1.0\n",
    "25   2.0\n",
    "'''\n",
    "\n",
    "'''\n",
    "Align DataFrames:\n",
    "When merging or comparing two DataFrames with different indices, reindexing can help align them.\n",
    "Add/Remove Data:\n",
    "Use reindexing to add missing rows/columns or remove unnecessary ones.\n",
    "Handle Missing Data:\n",
    "Introduce missing data intentionally or fill it using methods like forward or backward filling.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbab015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove entire row/column, use drop() function\n",
    "newdf.drop(0,axis=1)\n",
    "# here 0 is column name (NOT index)\n",
    "# default axis is axis=0 (row vaala)\n",
    "\n",
    "# BUT isse org me change NAHI hoga, for that\n",
    "newdf = newdf.drop(0,axis=1)\n",
    "#OR\n",
    "newdf.drop(0,axis=1,inplace=True)\n",
    "# usually copy vaale functions me inplace=True karne se they work as \n",
    "\n",
    "# after drop to reset index (bcs beech ke r/c gayab)\n",
    "newdf.reset_index()\n",
    "#but this adds another column called index which contains original indices. Agar vo nahi chahiye to:\n",
    "newdf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f58dcf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.612748</td>\n",
       "      <td>0.257399</td>\n",
       "      <td>0.551034</td>\n",
       "      <td>0.317615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E   F   G   H  11\n",
       "3  0.299098  0.612748  0.257399  0.551034  0.317615 NaN NaN NaN NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = newdf.loc[newdf['A']<0.3]\n",
    " # Returns rows where column 'A' has values less than 0.3\n",
    "# this means ki jaha jaha column ki value yeh condition satisfy karta hai, sirf vo vaala dataframe/vo vaale rown return karo\n",
    "\n",
    "newdf.loc[(newdf['A']<0.3) & (newdf['C']>0.1)]\n",
    "# Yaha logical AND use hoga - check SS\n",
    "\n",
    "## Filtering rows where Age is greater than 30\n",
    "filtered_df = df[df['Age'] > 28]\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac07057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "data = {'A': [0.2, 0.5, 0.1], 'C': [0.05, 0.2, 0.15]}\n",
    "newdf55 = pd.DataFrame(data)\n",
    "\n",
    "# Logical AND on Series\n",
    "condition = (newdf55['A'] < 0.3) & (newdf55['C'] > 0.1)\n",
    "print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17152db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  4\n",
       "1  2  5\n",
       "2  3  6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {0: [1, 2, 3], 1: [4, 5, 6]} \n",
    "dfl = pd.DataFrame(data)\n",
    "\n",
    "dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e4e6674",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['A']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25788\\400820598.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# We can also use df.dropna(axis=1) to remove columns or df.dropna(subset=[‘Column1’, ‘Column2’]) to drop rows with missing values in specific columns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Drop Rows Based on Specific Columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Check only column 'A' for NaN values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Keep rows with at least 2 non-NaN values. It overrides the how parameter if specified.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mresult_thresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6670\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['A']"
     ]
    }
   ],
   "source": [
    "# To remove rows or columns with missing values (NaN/Nat) from a DataFrame or Series.\n",
    "df.dropna()\n",
    "# row/column decide karne, use axis = 0/1 OR axis = 'index'/'columns'\n",
    "\n",
    "# to drop row/column as whole, use \n",
    "\n",
    "# We can also use df.dropna(axis=1) to remove columns or df.dropna(subset=[‘Column1’, ‘Column2’]) to drop rows with missing values in specific columns.\n",
    "\n",
    "# Drop Rows Based on Specific Columns\n",
    "# Check only column 'A' for NaN values - subset ek hi ho usme how = any/all doesnt really matter bcs ek hi column me check kar rahe hai\n",
    "result = df.dropna(subset=['A'])\n",
    "\n",
    "# Keep rows with at least 2 non-NaN values. It overrides the how parameter if specified.\n",
    "result_thresh = df.dropna(thresh=2)\n",
    "\n",
    "# Drop rows where any value is NaN - default - ie ek bhi missing value hua to poora row drop\n",
    "result_any = df.dropna(how='any')\n",
    "# Drop rows where all values are NaN\n",
    "result_all = df.dropna(how='all')\n",
    "\n",
    "# sometimes values may not exactly be Nan and may be custom missing values (ie user ne 'Missing' enter kar diya). So:\n",
    "# 1. dictionary hai to:\n",
    "df.replace('Missing',np.nan,inplace=True)\n",
    "# 2. csv file hai to:\n",
    "na_vals = ['NA', 'Missing']     #list of custom missing values\n",
    "df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent', na_values=na_vals)\n",
    "\n",
    "\n",
    "# To fill missing values(NaN) with a specified value, method, or other criteria.\n",
    "df_filled = df.fillna(0)\n",
    "df_filled = df.fillna('Missing')\n",
    "# Forward Fill (method='ffill') - propagates the last valid value forward to fill subsequent missing values (NaNs)\n",
    "# Subsequent missing values are replaced by the most recent non-missing value that appeared before them in the column (or row, depending on the axis).\n",
    "# Usi tarah backward fill (method='bfill')\n",
    "\n",
    "# limit parameter is used in conjunction with either method='ffill' or method='bfill' to restrict the number of missing values to fill. The limit parameter allows you to set a maximum number of consecutive missing values to fill in a given row or column\n",
    "# Once the limit is reached, the filling stops, and the remaining NaNs will remain unchanged.\n",
    "\n",
    "# To only replace empty values for one column, specify the column name for the DataFrame:\n",
    "df[\"Calories\"].fillna(130, inplace = True)\n",
    "#Also: median() and mode()\n",
    "x = df[\"Calories\"].mean()\n",
    "df[\"Calories\"].fillna(x, inplace = True)\n",
    "\n",
    "df.mean()\n",
    "# isse poore df (all series) pe lagega - so har numerical series ka median dega\n",
    "'''\n",
    "mean/median... me ignoring any NaN values. If a column contains only NaN values, the result for that column will be NaN.\n",
    "If you set skipna=False, pandas will not ignore NaN values and will return NaN for any column that contains a NaN.\n",
    "\n",
    "to deal with this, before calc mean/median:\n",
    "df_filled = df.fillna(0)  # Fill NaN values with 0\n",
    "mean_filled = df_filled.mean()\n",
    "'''\n",
    "\n",
    "# To identify missing values.  It returns a boolean DataFrame or Series, where each value is True if the corresponding value is NaN, and False otherwise.\n",
    "# isna() YA notna()\n",
    "# can also check ki koi value na gini gai hai ki nahi (custom na/missing)\n",
    "df_isna = df.isna()\n",
    "'''       A      B\n",
    "0  False  False\n",
    "1   True  False\n",
    "2  False   True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abhi lets say we want to find avg in a column\n",
    "df['YearsCode'].mean()\n",
    "# isme error dikhaya\n",
    "\n",
    "df['YearsCoded'].astype(float)\n",
    "# isse nan managed but 'less than 1 yr is giving error'2to3-script.py\n",
    "\n",
    "# now we look for unique values in series ki pata chale ki kis kis value ko handle karna hai\n",
    "df['YearsCoded'].unique()\n",
    "\n",
    "df['YearsCode'].replace('Less than 1 year', 0, inplace=True)\n",
    "df['YearsCode'].replace('Less than 1 year', 0, inplace=True)\n",
    "\n",
    "# abhi kar sakte hai\n",
    "df['YearsCode'] = df['YearsCode'].astype(float)\n",
    "df['YearsCode'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date and Time\n",
    "\n",
    "df.loc[0,'Date'].day_name()\n",
    "# 2020-03-13 20:00:00 - proper BUt\t2020-03-13 05-PM is incorrect\n",
    "# yeh error diya...it means ki datetime format me nahi hai\n",
    "\n",
    "#m1\n",
    "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d %I-%p ')\n",
    "# agar ho gaya to nice...agar nai ho paaya to, we need to pass a formatted string telling it ki string kaise format hui hai - check docum\n",
    "# i is for 12 hr clock and %p is for am/pm\n",
    "#m2\n",
    "d_parser = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %I-%p')  # convert string to datetime\n",
    "df = pd.read_csv('ETH_1h.csv', parse_dates=['Date'], date_parser=d_parser)\n",
    "\n",
    "\n",
    "df.loc[0,'Date'].day_name()\n",
    "# date deke, dayname batayega\n",
    "# poore series ke liye - here we created new column\n",
    "df['Day'] = df['Date'].dt.day_name()\n",
    "\n",
    "df['Dates'].min() \n",
    "df['Dates'].max()       #most recent date\n",
    "\n",
    "# we can subtract dates to find time btw them - timedelta return\n",
    "df['Dates'].max() - df['Dates'].min()\n",
    "\n",
    "\n",
    "filt = (df['Date']>='2019' & df['Date']<='2020')\n",
    "# upar stings use kiye but we can use datetimes as well\n",
    "filt = (df['Date'] >= pd.to_datetime('2019-01-01')) & (df['Date'] < pd.to_datetime('2020-01-01'))\n",
    "df.loc[filt]\n",
    "\n",
    "df.set_index('Date', inplace=True)\n",
    "df['2019']\n",
    "# isse vo automatically 2019 vaale de dega (poora speicfy karne ki zarurat nahi)\n",
    "'''\n",
    "Date\t\t\t\t\t\t\t\n",
    "2019-12-31 23:00:00\tETHUSD\t128.33\t128.69\t128.14\t128.54\t440678.91\tTuesday\n",
    "2019-12-31 22:00:00\tETHUSD\t128.38\t128.69\t127.95\t128.33\t554646.02\tTuesday'''\n",
    "\n",
    "\n",
    "df['2020-01':'2020-02']     # 2nd val is inclusive\n",
    "# yeh khud se month yr samaj jaayega\n",
    "df['2020-01':'2020-02']['Close'].mean()\n",
    "\n",
    "df['2020-01-01']['High'].max()\n",
    "# if we want to see data on daily basis than hourly basis(hourly is given)\n",
    "# we wanna see high value of stock by day - check docu\n",
    "highs = df['High'].resample('D').max() #isse series aayega\n",
    "highs['2020-01-01']\n",
    "\n",
    "# to resample mul columns at once\n",
    "df.resample('W') .mean()\n",
    "df.resample('W').agg({'Close': 'mean', 'High': 'max', 'Low': 'min', 'Volume': 'sum'})\n",
    "\n",
    "# plotting - within browser\n",
    "%matplotlib inline\n",
    "\n",
    "highs.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df['Country'] == 'India')\n",
    "india_df = df.loc[filt]\n",
    "\n",
    "india_df.to_csv('data/modified.csv')\n",
    "\n",
    "#tsv me comma ke badle tab seperated...csv me comma seperated \n",
    "india_df.to_csv('data/modified.tsv', sep='\\t')\n",
    "\n",
    "india_df.to_excel('data/modified.xlsx')\n",
    "\n",
    "test = pd.read_excel('data/modified.xlsx', index_col='Respondent')\n",
    "\n",
    "\n",
    "india_df.to_json('data/modified.json', orient='records', lines=True)\n",
    "# orient se list like instad of dict like\n",
    "test = pd.read_json('data/modified.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07428360",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Category': ['A', 'B', 'A', 'B'], 'Value': [10, 20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "'''\n",
    "  Category  Value\n",
    "0        A     10\n",
    "1        B     20\n",
    "2        A     30\n",
    "3        B     40\n",
    "'''\n",
    "\n",
    "# groupby involves splitting the obj, applying the func, combine results\n",
    "\n",
    "# Group data by 'Category' and calculate the sum\n",
    "grouped_sum = df.groupby('Category').sum()\n",
    "print(\"Sum:\\n\", grouped_sum)\n",
    "'''\n",
    "Sum:\n",
    "         Value\n",
    "Category       \n",
    "A            40\n",
    "B            60\n",
    "'''\n",
    "\n",
    "grouped_mean = df.groupby('Category')['Value'].mean()\n",
    "print(\"\\nMean:\\n\", grouped_mean)\n",
    "'''\n",
    "The groupby('Category') groups the data as before.\n",
    "['Value'] selects the Value column for calculation.\n",
    ".mean() computes the average for each group.\n",
    "\n",
    "Mean:\n",
    "Category\n",
    "A    20.0\n",
    "B    30.0\n",
    "Name: Value, dtype: float64\n",
    "'''\n",
    "\n",
    "# .agg() allows applying multiple aggregation functions ('sum' and 'mean') to each group.\n",
    "grouped_agg = df.groupby('Category').agg(['sum', 'mean'])\n",
    "print(\"\\nAggregated:\\n\", grouped_agg)\n",
    "'''\n",
    "Aggregated:\n",
    "           Value       \n",
    "            sum  mean\n",
    "Category              \n",
    "A            40  20.0\n",
    "B            60  30.0\n",
    "'''\n",
    "\n",
    "df.groupby(['country'])\n",
    "# isse ek obj return \n",
    "# groupby breaks data into diff groups\n",
    "country_grp = df.groupby(['Country'])\n",
    "country_grp.get_group('India')\n",
    "# df with saare India vale log in Country\n",
    "\n",
    "#M2\n",
    "filt = df['Country'] == 'India'\n",
    "df.loc[filt]\n",
    "\n",
    "\n",
    "'''\n",
    "df.loc[filt]['SocialMedia'].value_counts()\n",
    "WhatsApp                    2990\n",
    "YouTube                     1820\n",
    "LinkedIn                     955\n",
    "\n",
    "country_grp['SocialMedia'].value_counts()\n",
    "Country   SM \n",
    "Afg       fa  15\n",
    "          wh  10\n",
    "\n",
    "Ind       ins 20\n",
    "          wh  21\n",
    "\n",
    "country_grp['SocialMedia'].value_counts().head(50)\n",
    "isse 50 social media apps NOT 50 countries\n",
    "\n",
    "abhi agar india ke chahiye saare social media apps to:\n",
    "country_grp['SocialMedia'].value_counts().loc['India']\n",
    "\n",
    "this is more useful bcs we dont need to run a filter on eveery count individually\n",
    "'''\n",
    "country_grp['SocialMedia'].value_counts(normalize=True).loc['China']\n",
    "\n",
    "country_grp['ConvertedComp'].median().loc['Germany']\n",
    "\n",
    "# agar ek se zyada func use karne ho to use .agg (aggregate) \n",
    "country_grp['ConvertedComp'].agg(['median', 'mean']).loc['Canada']\n",
    "\n",
    "# country_grp['ConvertedComp'].agg(['median', 'mean']) - yeh poore df pe lagake series wise dega\n",
    "\n",
    "\n",
    "\n",
    "# we want to see ki kitne log use python in India\n",
    "#m1\n",
    "filt = df['Country'] == 'India'\n",
    "df.loc[filt]['LanguageWorkedWith'].str.contains('Python').sum()\n",
    "# df.loc[filt] returns the dataframe to we can see df.loc[filt] as a whole and us_df['column name]\n",
    "# str.contains() returns True False karke... sum() also works on boolean (true=1,false=0)\n",
    "\n",
    "'''\n",
    "isse error aayega - group me apply use karo\n",
    "country_grp['LanguageWorkedWith'].str.contains('Python').sum()\n",
    "'''\n",
    "country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\n",
    "isse pata chalega ki har country me kitne log use python\n",
    "\n",
    "if you wanna see % country use python ki afg me 10%..\n",
    "for that \n",
    "1. we will find ki har country se total kitne log programming karte hai\n",
    "country_respondents = df['Country'].value_counts()\n",
    "United States            20949\n",
    "India                     9061\n",
    "\n",
    "2. then see ki kitne log python use karte hai\n",
    "country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\n",
    "Country\n",
    "Afghanistan                              8\n",
    "Albania                                 23\n",
    "\n",
    "3. now concat them \n",
    "python_df = pd.concat([country_respondents, country_uses_python], axis='columns', sort=False)\n",
    "python_df.rename(columns={'Country': 'NumRespondents', 'LanguageWorkedWith': 'NumKnowsPython'}, inplace=True)\n",
    "NumRespondents\tNumKnowsPython\n",
    "United States\t20949\t10083\n",
    "India\t9061\t3105\n",
    "\n",
    "4. create new column\n",
    "python_df['PctKnowsPython'] = (python_df['NumKnowsPython']/python_df['NumRespondents']) * 100\n",
    "NumRespondents\tNumKnowsPython\tPctKnowsPython\n",
    "United States\t20949\t10083\t48.131176\n",
    "India\t9061\t3105\t34.267741\n",
    "\n",
    "can also do\n",
    "python_df['PctKnowsPython'] = python_df.apply(lambda row: (row['NumKnowsPython'] / row['NumRespondents']) * 100, axis=1)\n",
    "\n",
    "\n",
    "5. python_df.sort_values(by='PctKnowsPython', ascending=False, inplace=True)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "200c0f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category     A   B\n",
      "Date              \n",
      "2024-10-01  10  20\n",
      "2024-10-02  15  25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIndex (Date): Each unique value in the Date column becomes a row in the pivot table.\\nColumns (Category): Each unique value in the Category column becomes a column in the pivot table.\\nValues (Values): The Values column is aggregated (summed) for each combination of Date and Category.\\n\\nvalues=\\'Values\\': Specifies the column to aggregate (the Values column).\\nindex=\\'Date\\': Sets the row labels (Date column).\\ncolumns=\\'Category\\': Sets the column labels (Category column).\\naggfunc=\\'sum\\': Aggregates the values using the sum function.\\nfill_value=0 (varna Nan)\\n\\ndf = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\\n                         \"bar\", \"bar\", \"bar\", \"bar\"],\\n                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\\n                         \"one\", \"one\", \"two\", \"two\"],\\n                   \"C\": [\"small\", \"large\", \"large\", \"small\",\\n                         \"small\", \"large\", \"small\", \"small\",\\n                         \"large\"],\\n                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\\n                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\\ndf\\n     A    B      C  D  E\\n0  foo  one  small  1  2\\n1  foo  one  large  2  4\\n2  foo  one  large  2  5\\n3  foo  two  small  3  5\\n4  foo  two  small  3  6\\n5  bar  one  large  4  6\\n6  bar  one  small  5  8\\n7  bar  two  small  6  9\\n8  bar  two  large  7  9\\n\\ntable = pd.pivot_table(df, values=\\'D\\', index=[\\'A\\', \\'B\\'],\\n                       columns=[\\'C\\'], aggfunc=\"sum\")\\ntable\\nC        large  small\\nA   B\\nbar one    4.0    5.0\\n    two    7.0    6.0\\nfoo one    4.0    1.0\\n    two    NaN    6.0\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Date': ['2024-10-01', '2024-10-01', '2024-10-02', '2024-10-02'],\n",
    "    'Category': ['A', 'B', 'A', 'B'],\n",
    "    'Values': [10, 20, 15, 25]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "'''\n",
    "        Date Category  Values\n",
    "0  2024-10-01        A      10\n",
    "1  2024-10-01        B      20\n",
    "2  2024-10-02        A      15\n",
    "3  2024-10-02        B      25\n",
    "'''\n",
    "\n",
    "pivot_table = df.pivot_table(values='Values', index='Date', columns='Category', aggfunc='sum')\n",
    "print(pivot_table)\n",
    "\n",
    "# aggfunc={'D': \"mean\", 'E': \"mean\"})\n",
    "# 'E': [\"min\", \"max\", \"mean\"]})\n",
    "\n",
    "'''\n",
    "Category         A     B\n",
    "Date                    \n",
    "2024-10-01    10.0  20.0\n",
    "2024-10-02    15.0  25.0\n",
    "'''\n",
    "\n",
    "'''\n",
    "Index (Date): Each unique value in the Date column becomes a row in the pivot table.\n",
    "Columns (Category): Each unique value in the Category column becomes a column in the pivot table.\n",
    "Values (Values): The Values column is aggregated (summed) for each combination of Date and Category.\n",
    "\n",
    "values='Values': Specifies the column to aggregate (the Values column).\n",
    "index='Date': Sets the row labels (Date column).\n",
    "columns='Category': Sets the column labels (Category column).\n",
    "aggfunc='sum': Aggregates the values using the sum function.\n",
    "fill_value=0 (varna Nan)\n",
    "\n",
    "df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
    "                         \"bar\", \"bar\", \"bar\", \"bar\"],\n",
    "                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
    "                         \"one\", \"one\", \"two\", \"two\"],\n",
    "                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
    "                         \"small\", \"large\", \"small\", \"small\",\n",
    "                         \"large\"],\n",
    "                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "df\n",
    "     A    B      C  D  E\n",
    "0  foo  one  small  1  2\n",
    "1  foo  one  large  2  4\n",
    "2  foo  one  large  2  5\n",
    "3  foo  two  small  3  5\n",
    "4  foo  two  small  3  6\n",
    "5  bar  one  large  4  6\n",
    "6  bar  one  small  5  8\n",
    "7  bar  two  small  6  9\n",
    "8  bar  two  large  7  9\n",
    "\n",
    "table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
    "                       columns=['C'], aggfunc=\"sum\")\n",
    "table\n",
    "C        large  small\n",
    "A   B\n",
    "bar one    4.0    5.0\n",
    "    two    7.0    6.0\n",
    "foo one    4.0    1.0\n",
    "    two    NaN    6.0\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ID': [23, 43, 12, 13, 67, 89, 90, 56, 34],\n",
    "    'Name': ['Ram', 'Deep', 'Yash', 'Aman', 'Arjun', 'Aditya', 'Akash', 'Chalsea', 'Divya'],\n",
    "    'Marks': [89, 97, 45, 78, 56, 76, 81, 87, 100],\n",
    "    'Grade': ['B', 'A', 'F', 'C', 'E', 'C', 'B', 'B', 'A']\n",
    "})\n",
    "\n",
    "# Applying melt\n",
    "melted_df = pd.melt(df, id_vars=['ID', 'Name'], value_vars=['Marks', 'Grade'], var_name='Subject', value_name='Score')\n",
    "\n",
    "'''\n",
    "frame: The DataFrame you want to reshape.\n",
    "id_vars: The columns to keep fixed (i.e., the columns that won't be melted). These are essentially your \"identifier\" columns.\n",
    "value_vars: The columns to unpivot (melt). If not specified, it will melt all columns not included in id_vars.\n",
    "var_name: The name to give the new \"variable\" column (which will contain the names of the columns being melted).\n",
    "value_name: The name to give the new \"value\" column (which will contain the values from the columns being melted).\n",
    "col_level: If columns are a MultiIndex, this specifies which level to melt.'''\n",
    "\n",
    "'''\n",
    "   ID     Name Subject  Score\n",
    "0  23      Ram   Marks     89\n",
    "1  43     Deep   Marks     97\n",
    "2  12     Yash   Marks     45\n",
    "3  13     Aman   Marks     78\n",
    "4  67    Arjun   Marks     56\n",
    "5  89   Aditya   Marks     76\n",
    "6  90    Akash   Marks     81\n",
    "7  56  Chalsea   Marks     87\n",
    "8  34    Divya   Marks    100\n",
    "9  23      Ram   Grade      B\n",
    "10 43     Deep   Grade      A\n",
    "11 12     Yash   Grade      F\n",
    "12 13     Aman   Grade      C\n",
    "13 67    Arjun   Grade      E\n",
    "14 89   Aditya   Grade      C\n",
    "15 90    Akash   Grade      B\n",
    "16 56  Chalsea   Grade      B\n",
    "17 34    Divya   Grade      A\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3, 4], 'Score': [85, 90, 88]})\n",
    "\n",
    "result = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "An inner join returns only the rows that have matching keys in both DataFrames.\n",
    "\n",
    "   ID    Name  Score\n",
    "0   2     Bob     85\n",
    "1   3  Charlie     90\n",
    "'''\n",
    "\n",
    "result = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "An outer join returns all rows from both DataFrames, filling in NaN where there are no matches. can use fill=\n",
    "\n",
    "   ID    Name  Score\n",
    "0   1   Alice    NaN\n",
    "1   2     Bob   85.0\n",
    "2   3  Charlie   90.0\n",
    "3   4     NaN   88.0\n",
    "'''\n",
    "\n",
    "result = pd.merge(df1, df2, on='ID', how='left')\n",
    "print(result)\n",
    "\n",
    "# aise hi how = 'right also works\n",
    "\n",
    "'''\n",
    "A left join returns all rows from the left DataFrame and the matching rows from the right DataFrame. If no match is found, NaN is returned for missing values.\n",
    "\n",
    "   ID    Name  Score\n",
    "0   1   Alice    NaN\n",
    "1   2     Bob   85.0\n",
    "2   3  Charlie   90.0\n",
    "'''\n",
    "\n",
    "#  useful when the column names in the two DataFrames being merged are different.\n",
    "df1 = pd.DataFrame({\n",
    "    'EmpID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    'EmployeeID': [2, 3, 4],\n",
    "    'Score': [85, 90, 88]\n",
    "})\n",
    "\n",
    "result = pd.merge(df1, df2, left_on='EmpID', right_on='EmployeeID', how='inner')\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "   EmpID    Name  EmployeeID  Score\n",
    "0      2     Bob           2     85\n",
    "1      3  Charlie           3     90\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c03af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A  B\n",
      "Group1 0  1  3\n",
      "       1  2  4\n",
      "Group2 0  5  7\n",
      "       1  6  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, ...)\n",
    "\n",
    "'''\n",
    "axis: The axis along which to concatenate.\n",
    "axis=0 (default): Combine along rows (stacking vertically).\n",
    "axis=1: Combine along columns (side-by-side).\n",
    "keys: Adds hierarchical keys to the result, creating a MultiIndex.\n",
    "'''\n",
    "\n",
    "\n",
    "#Concatenating Along Rows (Default Behavior)\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "result = pd.concat([df1, df2])\n",
    "'''\n",
    "   A  B\n",
    "0  1  3\n",
    "1  2  4\n",
    "0  5  7\n",
    "1  6  8\n",
    "\n",
    "if ignore_index = True\n",
    "   A  B\n",
    "0  1  3\n",
    "1  2  4\n",
    "2  5  7\n",
    "3  6  8\n",
    "'''\n",
    "\n",
    "#Concatenating Along columns\n",
    "result = pd.concat([df1, df2], axis=1)\n",
    "'''\n",
    "   A  B  A  B\n",
    "0  1  3  5  7\n",
    "1  2  4  6  8\n",
    "'''\n",
    "\n",
    "# concat along rows matlab columns utne hi rahenge and concat along columns mean rows utne hi rahenge\n",
    "\n",
    "df3 = pd.DataFrame({'B': [9, 10], 'C': [11, 12]})\n",
    "result = pd.concat([df1, df3], join='inner')\n",
    "'''\n",
    "   B\n",
    "0  3\n",
    "1  4\n",
    "0  9\n",
    "1 10\n",
    "'''\n",
    "\n",
    "# Using keys creates a hierarchical index:\n",
    "result = pd.concat([df1, df2], keys=['Group1', 'Group2'])\n",
    "'''\n",
    "           A  B\n",
    "Group1 0   1  3\n",
    "       1   2  4\n",
    "Group2 0   5  7\n",
    "       1   6  8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3], 'Score': [85, 90]})\n",
    "\n",
    "\n",
    "result1 = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(result1)\n",
    "\n",
    "# Concatenate along rows\n",
    "result2 = pd.concat([df1, df2], ignore_index=True) \n",
    "print(result2) \n",
    "\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Score': [85, 90]})\n",
    "\n",
    "result3 = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(result3)\n",
    "\n",
    "'''\n",
    "   ID Name  Score\n",
    "0   2  Bob     85\n",
    "\n",
    "    ID   Name  Score\n",
    "0  1.0  Alice    NaN\n",
    "1  2.0    Bob    NaN\n",
    "2  2.0    NaN   85.0\n",
    "3  3.0    NaN   90.0\n",
    "\n",
    "   ID   Name  Score\n",
    "0   1  Alice     85\n",
    "1   2    Bob     90\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efc7222d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['B', 'A'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25788\\3058775447.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_no_duplicates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# How to decide ki kaunse basis/columns pe duplicates hatane hai\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Remove duplicates based on column 'A' and 'B'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_no_duplicates_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# so if A and B both are same tabhi hatega\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6815\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"inplace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6816\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ignore_index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6818\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6819\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6820\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6946\u001b[0m         \u001b[1;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6947\u001b[0m         \u001b[1;31m# key that doesn't exist.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6949\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6950\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6953\u001b[0m             \u001b[1;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Index(['B', 'A'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# To remove duplicates - first occurence sirf rahega\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# How to decide ki kaunse basis/columns pe duplicates hatane hai\n",
    "# Remove duplicates based on column 'A' and 'B' \n",
    "df_no_duplicates_A = df.drop_duplicates(subset=['A','B'])\n",
    "# so if A and B both are same tabhi hatega\n",
    "\n",
    "\n",
    "# default for keep is first\n",
    "# saare hatane ho to (keep=False)\n",
    "df_no_duplicates_last = df.drop_duplicates(keep='last')\n",
    "\n",
    "# Remove duplicates and reset the index\n",
    "df_no_duplicates_reset = df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "# To discover duplicates, we can use the duplicated() method.\n",
    "# The duplicated() method returns a Boolean values for each row:\n",
    "# Returns True for every row that is a duplicate, otherwise False:\n",
    "print(df.duplicated())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11ad4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories  duration\n",
      "0     False     False\n",
      "1     False     False\n",
      "2     False     False\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'B'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DataFrame.isnull() YA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Series.isnull() \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# The function returns a DataFrame or Series of boolean values (True or False)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39misnull())\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misnull())\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\voraj\\OneDrive\\Desktop\\Computer\\Python\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'B'"
     ]
    }
   ],
   "source": [
    "# DataFrame.isnull() YA\n",
    "# Series.isnull() \n",
    "\n",
    "# isnull() checks for Nan or None BUT in a pandas DataFrame or Series.\n",
    "# isnan() is only for Nan AND used with NumPy arrays or pandas Series that contain numerical data.\n",
    "\n",
    "\n",
    "# The function returns a DataFrame or Series of boolean values (True or False)\n",
    "\n",
    "print(df.isnull())\n",
    "print(df['B'].isnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8fe6826",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (7302043.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[90], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    newdf.loc[[:],['B']]=None\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "newdf.loc[:,['B']]=None\n",
    "newdf.loc[[:],['B']]=None\n",
    "newdf.loc[[1:2],['B']]=None\n",
    "newdf.loc[1:2,['B']]=100\n",
    "\n",
    "# isme slicing me [] mat lagana, so line 2 and 3 are invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59dcab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaT in pandas stands for Not a Time and is used to represent missing or null values in datetime object\n",
    "\n",
    "df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "                   \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "                   \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
    "                            pd.NaT]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a2dc6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   name    3 non-null      object        \n",
      " 1   toy     2 non-null      object        \n",
      " 2   born    1 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01c1fa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    4\n",
      "b    2\n",
      "c    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to count the frequency of unique values in a Series\n",
    "# It returns a Series where the index is the unique values from the original Series, and the corresponding values are the count of occurrences of each unique value.\n",
    "\n",
    "df['toy'].value_counts()\n",
    "\n",
    "# to get frequency of each value ya kitne yes/no ...\n",
    "data = pd.Series(['a', 'b', 'a', 'c', 'b', 'a', 'a',None])\n",
    "count = data.value_counts()\n",
    "print(count)\n",
    "\n",
    "# Get the relative frequencies - percentages me (normalize=True) - The counts are now proportions of the total (summing to 1). \n",
    "normalized_count = data.value_counts(normalize=True)\n",
    "df['SocialMedia'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Count values including NaN - varma NaN vale nahi gine jaate\n",
    "count_with_na = data.value_counts(dropna=False)\n",
    "\n",
    "# bins ke liye = bins=5 will divide the range into 5 equal intervals\n",
    "# ya bins=[0, 10, 20, 30] would create 3 bins: (0-10), (10-20), and (20-30).\n",
    "\n",
    "# sort:\n",
    "# If True (default), the results are sorted by the counts in descending order.\n",
    "# If False, it returns the counts in the order the unique values appear.\n",
    "\n",
    "# The ascending parameter controls the sort order when sorting is enabled (i.e., when sort=True). By default, pandas sorts the data in descending order, but you can change that to ascending order.\n",
    "\n",
    "# ek column me kitne non-NA (non-missing) entries hai\n",
    "df['ConvertedComp'].count()\n",
    "# 0\n",
    "\n",
    "# isme total rows in a column, including missing values\n",
    "len(df['ConvertedComp'])\n",
    "# Count missing values\n",
    "missing = df['ConvertedComp'].isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6374a9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      toy        born      \n",
       "Alfred    NaN        NaT           1\n",
       "Batman    Batmobile  1940-04-25    1\n",
       "Catwoman  Bullwhip   NaT           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2a73c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toy\n",
       "NaN          1\n",
       "Batmobile    1\n",
       "Bullwhip     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toy'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a5466a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.std of        name        toy       born\n",
       "0    Alfred        NaN        NaT\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('file.xlsx', sheet_name=0) # default is 0, yaha sheetname as string bhi ho sakta hai\n",
    "# Read multiple sheets (by names or indices)\n",
    "df_dict = pd.read_excel('file.xlsx', sheet_name=['Sheet1', 'Sheet2'])\n",
    "\n",
    "# Read specific columns from the Excel file\n",
    "df = pd.read_excel('file.xlsx', usecols=['A', 'B'])\n",
    "\n",
    "# Skip the first 2 rows and read the rest\n",
    "df = pd.read_excel('file.xlsx', skiprows=2)\n",
    "\n",
    "# Read the data and set a specific column as the index\n",
    "df = pd.read_excel('file.xlsx', index_col='ID')\n",
    "\n",
    "# Automatically parse dates in a specific column\n",
    "df = pd.read_excel('file.xlsx', parse_dates=['DateColumn'])\n",
    "\n",
    "# Read an Excel file directly from a URL\n",
    "df = pd.read_excel('https://example.com/file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write to i.e. store in excel file\n",
    "\n",
    "# If this file does not already exist, it will be created.\n",
    "dataframe = pd.DataFrame(dct)  \n",
    "dataframe.to_excel(\"output.xlsx\")\n",
    "df1.to_excel(\"output.xlsx\", sheet_name='Sheet_name_2')  \n",
    "# Here new sheet created .If a sheet with this name already exists, it will be replaced unless specified otherwise.\n",
    "# doubt - baaki ke sheets will be deleted??\n",
    "\n",
    "#If you wish to write to more than one sheet in the workbook, it is necessary to specify an ExcelWriter object:\n",
    "df2 = df1.copy()\n",
    "with pd.ExcelWriter('output.xlsx') as writer:  \n",
    "    df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
    "    df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
    "\n",
    "# ExcelWriter can also be used to append to an existing Excel file:\n",
    "with pd.ExcelWriter('output.xlsx', mode='a') as writer:  \n",
    "    df1.to_excel(writer, sheet_name='Sheet_name_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['rm']]:\n",
    "\n",
    "# This line extracts the column named 'rm' from the DataFrame a and stores it in a new variable X.\n",
    "# The double square brackets [['rm']] are used to select the column 'rm' as a DataFrame (not a Series). If you wanted to select it as a Series, you could use single square brackets: a['rm']."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
